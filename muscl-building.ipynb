{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e983b244",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-06-27T23:24:51.386723Z",
     "iopub.status.busy": "2023-06-27T23:24:51.385921Z",
     "iopub.status.idle": "2023-06-27T23:24:51.417715Z",
     "shell.execute_reply": "2023-06-27T23:24:51.416383Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.041034,
     "end_time": "2023-06-27T23:24:51.420432",
     "exception": false,
     "start_time": "2023-06-27T23:24:51.379398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/6june-210/bheem3.wav\n",
      "/kaggle/input/6june-210/thi1.wav\n",
      "/kaggle/input/6june-210/tha2.wav\n",
      "/kaggle/input/6june-210/thom1.wav\n",
      "/kaggle/input/6june-210/thi3.wav\n",
      "/kaggle/input/6june-210/bheem1-2.wav\n",
      "/kaggle/input/6june-210/thom2.wav\n",
      "/kaggle/input/6june-210/chappu3.wav\n",
      "/kaggle/input/6june-210/chappu1.wav\n",
      "/kaggle/input/6june-210/tha_thi_thom_num2.wav\n",
      "/kaggle/input/6june-210/chappu4.wav\n",
      "/kaggle/input/6june-210/thi2.wav\n",
      "/kaggle/input/6june-210/ta2.wav\n",
      "/kaggle/input/6june-210/ki3.wav\n",
      "/kaggle/input/6june-210/ta1.wav\n",
      "/kaggle/input/6june-210/dhin1.wav\n",
      "/kaggle/input/6june-210/tha_thi_thom_num_4.wav\n",
      "/kaggle/input/6june-210/ki2.wav\n",
      "/kaggle/input/6june-210/bheem1.wav\n",
      "/kaggle/input/6june-210/thom3.wav\n",
      "/kaggle/input/6june-210/tha_thi_thom_num_3.wav\n",
      "/kaggle/input/6june-210/tha_thi_thom_num_2_2.wav\n",
      "/kaggle/input/6june-210/bheem2.wav\n",
      "/kaggle/input/6june-210/dhin2.wav\n",
      "/kaggle/input/6june-210/tha_thi_thom_num1.wav\n",
      "/kaggle/input/6june-210/ki1.wav\n",
      "/kaggle/input/6june-210/dheem2.wav\n",
      "/kaggle/input/6june-210/tha_thi_thom_num_2.wav\n",
      "/kaggle/input/6june-210/thi4.wav\n",
      "/kaggle/input/6june-210/chappu2.wav\n",
      "/kaggle/input/6june-210/tha1.wav\n",
      "/kaggle/input/6june-210/num1.wav\n",
      "/kaggle/input/6june-210/num2.wav\n",
      "/kaggle/input/6june-210/dheem3.wav\n",
      "/kaggle/input/6june-210/dheem1.wav\n",
      "/kaggle/input/mridangamdataset/__results__.html\n",
      "/kaggle/input/mridangamdataset/spectrogram.png\n",
      "/kaggle/input/mridangamdataset/__notebook__.ipynb\n",
      "/kaggle/input/mridangamdataset/__output__.json\n",
      "/kaggle/input/mridangamdataset/custom.css\n",
      "/kaggle/input/mridangamdataset/__results___files/__results___34_2.png\n",
      "/kaggle/input/mridangamdataset/__results___files/__results___33_2.png\n",
      "/kaggle/input/mridangamdataset/__results___files/__results___33_1.png\n",
      "/kaggle/input/mridangamdataset/__results___files/__results___33_0.png\n",
      "/kaggle/input/mridangamdataset/__results___files/__results___34_1.png\n",
      "/kaggle/input/mridangamdataset/__results___files/__results___34_3.png\n",
      "/kaggle/input/mridangamdataset/__results___files/__results___34_0.png\n",
      "/kaggle/input/mridangamdataset/__results___files/__results___32_0.png\n",
      "/kaggle/input/mridangam-dataset-4junesac/dheem.wav\n",
      "/kaggle/input/mridangam-dataset-4junesac/chapu.wav\n",
      "/kaggle/input/mridangam-dataset-4junesac/ta.wav\n",
      "/kaggle/input/mridangam-dataset-4junesac/thom2.wav\n",
      "/kaggle/input/mridangam-dataset-4junesac/thikutharikidathaka.wav\n",
      "/kaggle/input/mridangam-dataset-4junesac/thom3.wav\n",
      "/kaggle/input/mridangam-dataset-4junesac/Dhi.wav\n",
      "/kaggle/input/mridangam-dataset-4junesac/thi.wav\n",
      "/kaggle/input/mridangam-dataset-4junesac/num.wav\n",
      "/kaggle/input/mridangam-dataset-4junesac/chapu2.wav\n",
      "/kaggle/input/mridangam-dataset-4junesac/dheem2.wav\n",
      "/kaggle/input/mridangam-dataset-4junesac/thom.wav\n",
      "/kaggle/input/mridangam-dataset-4junesac/Tha.wav\n",
      "/kaggle/input/mridangam-dataset-4junesac/Dheem3.wav\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ca06fa",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-06-27T23:24:51.428413Z",
     "iopub.status.busy": "2023-06-27T23:24:51.428115Z",
     "iopub.status.idle": "2023-06-27T23:25:19.462945Z",
     "shell.execute_reply": "2023-06-27T23:25:19.462090Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 28.041569,
     "end_time": "2023-06-27T23:25:19.465641",
     "exception": false,
     "start_time": "2023-06-27T23:24:51.424072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mirdata\r\n",
      "  Downloading mirdata-0.3.7-py3-none-any.whl (14.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from mirdata) (4.64.1)\r\n",
      "Requirement already satisfied: librosa>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from mirdata) (0.10.0.post2)\r\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.10/site-packages (from mirdata) (1.23.5)\r\n",
      "Collecting jams (from mirdata)\r\n",
      "  Downloading jams-0.3.4.tar.gz (51 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from mirdata) (2.28.2)\r\n",
      "Collecting pretty-midi>=0.2.8 (from mirdata)\r\n",
      "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting chardet (from mirdata)\r\n",
      "  Downloading chardet-5.1.0-py3-none-any.whl (199 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mirdata) (5.4.1)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from mirdata) (1.10.1)\r\n",
      "Requirement already satisfied: h5py>=2.10.0 in /opt/conda/lib/python3.10/site-packages (from mirdata) (3.8.0)\r\n",
      "Requirement already satisfied: smart-open>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from mirdata) (6.3.0)\r\n",
      "Requirement already satisfied: Deprecated>=1.2.13 in /opt/conda/lib/python3.10/site-packages (from mirdata) (1.2.13)\r\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from mirdata) (1.5.3)\r\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from Deprecated>=1.2.13->mirdata) (1.14.1)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.8.0->mirdata) (3.0.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.8.0->mirdata) (1.2.2)\r\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.8.0->mirdata) (1.2.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.8.0->mirdata) (5.1.1)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.8.0->mirdata) (0.57.0)\r\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.8.0->mirdata) (0.12.1)\r\n",
      "Requirement already satisfied: pooch<1.7,>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.8.0->mirdata) (1.6.0)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.8.0->mirdata) (0.3.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.8.0->mirdata) (4.5.0)\r\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.8.0->mirdata) (0.2)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.8.0->mirdata) (1.0.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->mirdata) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->mirdata) (2023.3)\r\n",
      "Collecting mido>=1.1.16 (from pretty-midi>=0.2.8->mirdata)\r\n",
      "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from pretty-midi>=0.2.8->mirdata) (1.16.0)\r\n",
      "Requirement already satisfied: sortedcontainers>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from jams->mirdata) (2.4.0)\r\n",
      "Requirement already satisfied: jsonschema>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from jams->mirdata) (4.17.3)\r\n",
      "Collecting mir_eval>=0.5 (from jams->mirdata)\r\n",
      "  Downloading mir_eval-0.7.tar.gz (90 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->mirdata) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->mirdata) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->mirdata) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->mirdata) (2023.5.7)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0.0->jams->mirdata) (23.1.0)\r\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0.0->jams->mirdata) (0.19.3)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from mir_eval>=0.5->jams->mirdata) (0.18.3)\r\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa>=0.8.0->mirdata) (0.40.0)\r\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from pooch<1.7,>=1.0->librosa>=0.8.0->mirdata) (1.4.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pooch<1.7,>=1.0->librosa>=0.8.0->mirdata) (21.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa>=0.8.0->mirdata) (3.1.0)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa>=0.8.0->mirdata) (1.15.1)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.8.0->mirdata) (2.21)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pooch<1.7,>=1.0->librosa>=0.8.0->mirdata) (3.0.9)\r\n",
      "Building wheels for collected packages: pretty-midi, jams, mir_eval\r\n",
      "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pretty-midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592303 sha256=d49bff45b6ece7997aeb7d7c5f8ef5ae76fe670432a1fc8153a0024714032e57\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\r\n",
      "  Building wheel for jams (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for jams: filename=jams-0.3.4-py3-none-any.whl size=64923 sha256=3347f9970435d92197029833dedc1b6f32c558baf9f6fda86b70f9b0f858eaaf\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/28/9a/f7/fb386b6bc5a75a3ef198a50e98b221e94a381472332b65cf24\r\n",
      "  Building wheel for mir_eval (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for mir_eval: filename=mir_eval-0.7-py3-none-any.whl size=100721 sha256=7a451f9aacd0d93fa49768994fb781dbb80de5819231b6733cd8ec9355fdba2c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/2f/0d/dda9c4c77a170e21356b6afa2f7d9bb078338634ba05d94e3f\r\n",
      "Successfully built pretty-midi jams mir_eval\r\n",
      "Installing collected packages: mido, pretty-midi, chardet, mir_eval, jams, mirdata\r\n",
      "Successfully installed chardet-5.1.0 jams-0.3.4 mido-1.2.10 mir_eval-0.7 mirdata-0.3.7 pretty-midi-0.2.10\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting noisereduce\r\n",
      "  Downloading noisereduce-2.0.1-py3-none-any.whl (15 kB)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from noisereduce) (1.10.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from noisereduce) (3.6.3)\r\n",
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (from noisereduce) (0.10.0.post2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from noisereduce) (1.23.5)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from noisereduce) (4.64.1)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa->noisereduce) (3.0.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa->noisereduce) (1.2.2)\r\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa->noisereduce) (1.2.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa->noisereduce) (5.1.1)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa->noisereduce) (0.57.0)\r\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from librosa->noisereduce) (0.12.1)\r\n",
      "Requirement already satisfied: pooch<1.7,>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa->noisereduce) (1.6.0)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa->noisereduce) (0.3.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa->noisereduce) (4.5.0)\r\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa->noisereduce) (0.2)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa->noisereduce) (1.0.5)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->noisereduce) (1.0.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->noisereduce) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->noisereduce) (4.39.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->noisereduce) (1.4.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->noisereduce) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->noisereduce) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->noisereduce) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->noisereduce) (2.8.2)\r\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa->noisereduce) (0.40.0)\r\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from pooch<1.7,>=1.0->librosa->noisereduce) (1.4.4)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch<1.7,>=1.0->librosa->noisereduce) (2.28.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.16.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa->noisereduce) (3.1.0)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa->noisereduce) (1.15.1)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->noisereduce) (2.21)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa->noisereduce) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa->noisereduce) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa->noisereduce) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa->noisereduce) (2023.5.7)\r\n",
      "Installing collected packages: noisereduce\r\n",
      "Successfully installed noisereduce-2.0.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install mirdata\n",
    "!pip install noisereduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7e7c59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T23:25:19.480708Z",
     "iopub.status.busy": "2023-06-27T23:25:19.480288Z",
     "iopub.status.idle": "2023-06-27T23:25:19.485396Z",
     "shell.execute_reply": "2023-06-27T23:25:19.484332Z"
    },
    "papermill": {
     "duration": 0.014719,
     "end_time": "2023-06-27T23:25:19.487230",
     "exception": false,
     "start_time": "2023-06-27T23:25:19.472511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# plt.imshow(mpimg.imread(\"/kaggle/input/mridangamdataset/spectrogram.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "047ca591",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T23:25:19.505128Z",
     "iopub.status.busy": "2023-06-27T23:25:19.504754Z",
     "iopub.status.idle": "2023-06-27T23:25:21.834196Z",
     "shell.execute_reply": "2023-06-27T23:25:21.832711Z"
    },
    "papermill": {
     "duration": 2.341561,
     "end_time": "2023-06-27T23:25:21.836833",
     "exception": false,
     "start_time": "2023-06-27T23:25:19.495272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractorSVM: no classifier models were configured by default\n"
     ]
    }
   ],
   "source": [
    "# Imports are made in MuSCl Preprocessor's __init__ function\n",
    "from essentia.standard import Windowing, OnsetDetection,FFT,CartesianToPolar,FrameGenerator,Onsets,AudioOnsetsMarker,StereoMuxer, OnsetDetectionGlobal\n",
    "from tempfile import TemporaryDirectory\n",
    "import essentia\n",
    "import mirdata\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import essentia.standard as estd\n",
    "import numpy as np\n",
    "import noisereduce as nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ac1e022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T23:25:21.854415Z",
     "iopub.status.busy": "2023-06-27T23:25:21.854066Z",
     "iopub.status.idle": "2023-06-27T23:25:21.876472Z",
     "shell.execute_reply": "2023-06-27T23:25:21.875897Z"
    },
    "papermill": {
     "duration": 0.035022,
     "end_time": "2023-06-27T23:25:21.878992",
     "exception": false,
     "start_time": "2023-06-27T23:25:21.843970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MuSClPreprocessor:\n",
    "    '''\n",
    "    Preprocessor class for MuSCl or any other music signal,\n",
    "    check the documentation of each function for usage\n",
    "    \n",
    "    Size of the output signal depends on the size of the input file in milli seconds related to the sampling rate applied. \n",
    "    The basic preprocessor function does not change the size of the input file.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            from essentia.standard import Windowing, OnsetDetection,FFT,CartesianToPolar,FrameGenerator,Onsets,AudioOnsetsMarker,StereoMuxer, OnsetDetectionGlobal\n",
    "            from tempfile import TemporaryDirectory\n",
    "            import essentia\n",
    "            import mirdata\n",
    "            import pandas as pd\n",
    "            import librosa\n",
    "            import essentia.standard as estd\n",
    "            import numpy as np\n",
    "            import noisereduce as nr\n",
    "        except Exception as e:\n",
    "            print(\"Terminated, As the following error was raised\",e)\n",
    "            \n",
    "    def BasicPreprocessor(self,filename=None,audio=None,inputsamplerate=44100,noise_remove=False,sr=44100,normalize_type='librosa',target_peak=0.9,target_rms=0.5):\n",
    "        '''\n",
    "        Does Resampling,Noise Removal, Normalization and Framing\n",
    "        Parameters:\n",
    "        \n",
    "        Resampling rate is generally 44100, can be changed as an input\n",
    "        sr: Resampling rate\n",
    "        normalize_type: Type of normalization options: librosa | peak-normalize | rms\n",
    "            for peak-normalize option, target_peak is preferred to be 0.9\n",
    "            for rms-normalization option, target_rms is preferred to be 0.5\n",
    "        target_peak: value for peak-normalize option, if normalize_type == 'peak-normalize'\n",
    "        target_rms: value for rms-normalization option if normalize_type == 'rms'\n",
    "        \n",
    "        Returns audio_signal\n",
    "        '''\n",
    "        # Resampling part\n",
    "        if audio==None and filename==None:\n",
    "            print(\"Error, Please give any one of the parameters as input - audio or filename\")\n",
    "            return\n",
    "        if audio==None:\n",
    "            audio,inputsamplerate=librosa.load(filename,sr=sr,res_type='HQ')\n",
    "            \n",
    "        \n",
    "        # can do resampling by giving alternate sr, default is 44100,\n",
    "        # res_type is a parameter 'HQ' can be given for high quality\n",
    "        # returns single array output calling for the amplitude values at \n",
    "        # each point of time for a mono audio signal.\n",
    "        \n",
    "        # Normalization part\n",
    "        if normalize_type=='librosa':\n",
    "            audio=librosa.util.normalize(audio)\n",
    "        elif normalize_type=='peak-normalize':\n",
    "            max_amplitude = np.max(np.abs(audio))\n",
    "            audio = audio * (target_peak / max_amplitude)\n",
    "        elif normalize_type=='rms':\n",
    "            rms = np.sqrt(np.mean(audio**2))\n",
    "            audio = audio * (target_rms / rms)\n",
    "        \n",
    "        # noise-removal part\n",
    "        if noise_remove:\n",
    "            audio=nr.reduce_noise(audio,sr=sr)\n",
    "        \n",
    "        return audio\n",
    "    \n",
    "    def apply_window(self,audio_signal, window_type='hamming'):\n",
    "        '''\n",
    "        Applying windowing functions\n",
    "        Parameters:\n",
    "        audio_signal: vector for audio signal\n",
    "            librosa.load output or estd.MonoLoader().compute() output can be an input\n",
    "        window_type: hann | hamming | rectangular | blackman\n",
    "        \n",
    "        '''\n",
    "        windows = {\n",
    "            'rectangular': np.ones_like(audio_signal),\n",
    "            'hann': np.hanning(len(audio_signal)),\n",
    "            'hamming': np.hamming(len(audio_signal)),\n",
    "            'blackman': np.blackman(len(audio_signal))\n",
    "        }\n",
    "        window = windows.get(window_type, np.ones_like(audio_signal))\n",
    "        return audio_signal * window\n",
    "\n",
    "    def frame_signal(self,signal, frame_size=1024, hop_size=512):\n",
    "        '''\n",
    "        Function to generate frames\n",
    "        Parameters:\n",
    "        signal: vector[real] \n",
    "        frame_size: Size of each in samples\n",
    "        hop_size: Hop size between consecutive frames in samples\n",
    "        '''\n",
    "        num_frames = 1 + int((len(signal) - frame_size) / hop_size)\n",
    "        frames = np.zeros((num_frames, frame_size))\n",
    "        for i in range(num_frames):\n",
    "            start = i * hop_size\n",
    "            end = start + frame_size\n",
    "            frames[i] = signal[start:end]\n",
    "        return frames\n",
    "    \n",
    "    def compute_cqt(self,audio_signal,sr,n_bins=84,hop_length=512,n_frames=100):\n",
    "        '''\n",
    "        Parameters:\n",
    "        audio_file: music file in .wav format \n",
    "        sr: sample_rate of the audio signal\n",
    "        n_bins: required number of bins\n",
    "        hop_length: hop length in the signal\n",
    "        n_frames: number of frames\n",
    "\n",
    "        returns:\n",
    "        CQ-Transform of the input, np.ndarray\n",
    "        '''\n",
    "\n",
    "        cqt = librosa.cqt(audio_signal, sr=sr, n_bins=n_bins, hop_length=hop_length, bins_per_octave=12)\n",
    "        return cqt\n",
    "    \n",
    "    def onset_detection(self,filename=None,audio=None,sr=44100,complex=True,hfc=False):\n",
    "        '''\n",
    "        This function detects onsets in the file using either of the complex or simple Onset Detection functions\n",
    "        from essentia.standard. All the required imports should be done to use this file\n",
    "        \n",
    "        Parameters:\n",
    "        filename: default=None. the location of the audio file for onset detection. Flexible, can provide audio vector instead\n",
    "        audio: default=None. audio signal of the music file. Flexible, can give filename instead. But one of them has to be give.\n",
    "        sr: deafult=44100. sample rate of the input\n",
    "        complex: default=True. If True, complex Onset Detection Function type from essentia.standard.OnsetDetection shall be used\n",
    "        hfc: default=False. If True, Simple Onset Detection Function type from essentia.standard.OnsetDetection shall be used\n",
    "        \n",
    "        Returns:\n",
    "        A list of lists and MUX audio signal, each list denoting the starting and ending indices of frames of an audio file where the onsets were detected.\n",
    "        If a single onset is detected the output is a list of a single list and the audio MUX file.\n",
    "        The MUX file is a (n,2) array where the first column indicates the actual signal vector values and the\n",
    "        second column indicates where the onsets were detected.\n",
    "        '''\n",
    "        \n",
    "        if audio==None and filename==None:\n",
    "            print(\"Error, provide atleast one of the parameters - filename, audio\")\n",
    "            return [[]]\n",
    "        \n",
    "        if audio==None:\n",
    "            audio=librosa.load(filename,sr=44100)[0] # change this to a parameter input \n",
    "        \n",
    "        # We need the auxilary algorithms to compute magnitude and phase.\n",
    "        w = Windowing(type='hann')\n",
    "        fft = FFT() # Outputs a complex FFT vector.\n",
    "        c2p = CartesianToPolar() # Converts it into a pair of magnitude and phase vectors.\n",
    "        # Compute both ODF frame by frame. Store results to a Pool.\n",
    "        pool = essentia.Pool()\n",
    "        # Add onset markers to the audio and save it to a file.\n",
    "        # We use beeps instead of white noise and stereo signal as it's more distinctive.\n",
    "        onsets=Onsets()\n",
    "        # We want to keep beeps in a separate audio channel.\n",
    "        # Add them to a silent audio and use the original audio as another channel. Mux both into a stereo signal.\n",
    "\n",
    "        silence = [0.] * len(audio)\n",
    "        if complex:\n",
    "            od_complex = OnsetDetection(method='complex')\n",
    "            for frame in FrameGenerator(audio, frameSize=1024, hopSize=512):\n",
    "                magnitude, phase = c2p(fft(w(frame)))\n",
    "                pool.add('odf.complex', od_complex(magnitude, phase))\n",
    "            onsets_complex = onsets(essentia.array([pool['odf.complex']]), [1])\n",
    "            beeps_complex = AudioOnsetsMarker(onsets=onsets_complex, type='beep')(silence)\n",
    "            audio_ = StereoMuxer()(audio, beeps_complex)\n",
    "            indices=np.where(audio_[:,1]!=0)\n",
    "\n",
    "        else:\n",
    "            for frame in FrameGenerator(audio, frameSize=1024, hopSize=512):\n",
    "                magnitude, phase = c2p(fft(w(frame)))\n",
    "                pool.add('odf.hfc', od_hfc(magnitude, phase))\n",
    "            onsets_hfc = onsets(# This algorithm expects a matrix, not a vector.\n",
    "                                essentia.array([pool['odf.hfc']]),\n",
    "                                # You need to specify weights, but if we use only one ODF\n",
    "                                # it doesn't actually matter which weight to give it\n",
    "                                [1])\n",
    "            od_hfc=OnsetDetection(method='hfc')\n",
    "            beeps_hfc = AudioOnsetsMarker(onsets=onsets_hfc, type='beep')(silence)\n",
    "            audio_ = StereoMuxer()(audio, beeps_hfc)\n",
    "            indices=np.where(audio_[:,1]!=0)\n",
    "\n",
    "        if ((max(indices[0])-min(indices[0]))+1)==indices[0].shape:\n",
    "            return [[min(indices[0]),max(indices[0])]],audio_\n",
    "        else:\n",
    "            l=[]\n",
    "            l.append([indices[0][0],])\n",
    "            for i in range(1,len(indices[0])):\n",
    "                if indices[0][i]!=(indices[0][i-1]+1):\n",
    "                    l[-1].append(indices[0][i-1])\n",
    "                    l.append([indices[0][i],])\n",
    "            l[-1].append(indices[0][-1])\n",
    "            return l,audio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66f0591d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T23:25:21.894100Z",
     "iopub.status.busy": "2023-06-27T23:25:21.893475Z",
     "iopub.status.idle": "2023-06-27T23:25:21.906095Z",
     "shell.execute_reply": "2023-06-27T23:25:21.905353Z"
    },
    "papermill": {
     "duration": 0.022443,
     "end_time": "2023-06-27T23:25:21.908492",
     "exception": false,
     "start_time": "2023-06-27T23:25:21.886049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Music Stroke Classification class written by using compiam, other research papers and dataset from mirdata\n",
    "class MuSCl:\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            from essentia.standard import Windowing, OnsetDetection,FFT,CartesianToPolar,FrameGenerator,Onsets,AudioOnsetsMarker,StereoMuxer, OnsetDetectionGlobal\n",
    "            from tempfile import TemporaryDirectory\n",
    "            import essentia\n",
    "            import mirdata\n",
    "            import pandas as pd\n",
    "            import librosa\n",
    "            import essentia.standard as estd\n",
    "            import numpy as np\n",
    "            import noisereduce as nr\n",
    "        except Exception as e:\n",
    "            print(\"Terminated, As the following error was raised\",e)\n",
    "        self.dataset=None\n",
    "        self.dataset_loaded=False\n",
    "    \n",
    "    def load_dataset(self,dataset_name=\"mridangam_stroke\",version=\"default\",data_home=None,download=True):\n",
    "        '''Load_dataset function to download the dataset and load it as an class object\n",
    "        \n",
    "        Parameters:\n",
    "        dataset_name : Dataset name according to MIR datasets\n",
    "        version : Version type of the dataset required\n",
    "        data_home : if dataset is already downloaded, just import from data_home or want to downlad to a particular location in directory can give the location\n",
    "        download : True, dataset is downloaded from mirdata. False, dataset is already downloaded\n",
    "        \n",
    "        returns None, loads the downloaded dataset in variables\n",
    "        '''\n",
    "        self.dataset=mirdata.initialize(\n",
    "                        dataset_name=dataset_name, data_home=data_home, version=version\n",
    "                            )\n",
    "        self.data_home = self.dataset.data_home # where the data is stored after downloading\n",
    "        if download:\n",
    "            self.dataset.download()\n",
    "            self.dataset.validate()\n",
    "        else:\n",
    "            if not os.path.exists(os.path.join(self.data_home, \"mridangam_stroke_1.5\")):\n",
    "                raise ValueError(\n",
    "                    \"Dataset not found, please re-run load_dataset with download=True\"\n",
    "                )\n",
    "        if dataset_name==\"mridangam_stroke\":\n",
    "            self.dataset_loaded=True\n",
    "            self.mridangam_ids = self.dataset.track_ids  # Load Mridangam IDs\n",
    "            self.mridangam_tracks = self.dataset.load_tracks()  # Load Mridangam data\n",
    "            self.stroke_names = self.get_strokes()\n",
    "            self.stroke_dict = {item: [] for item in self.stroke_names}\n",
    "            for i in self.mridangam_ids:\n",
    "                self.stroke_dict[self.mridangam_tracks[i].stroke_name].append(\n",
    "                    self.mridangam_tracks[i].audio_path\n",
    "                    )\n",
    "            \n",
    "            \n",
    "    def get_strokes(self):\n",
    "        \"\"\"List available mridangam strokes in the dataset.\n",
    "\n",
    "        :returns: list of strokes in the datasets.\n",
    "        \"\"\"\n",
    "        if not self.dataset_loaded:\n",
    "            raise ValueError('Dataset Not Loaded') # Change according to convenience\n",
    "        stroke_names = []\n",
    "        for i in self.mridangam_ids:\n",
    "            stroke_names.append(self.mridangam_tracks[i].stroke_name)\n",
    "        return list(np.unique(stroke_names))\n",
    "    def dict_strokes(self):\n",
    "        \"\"\"List and convert to indexed dict the available mridangam strokes in the dataset.\n",
    "\n",
    "        :returns: dict with strokes as values and unique integer as keys.\n",
    "        \"\"\"\n",
    "        if not self.dataset_loaded:\n",
    "            raise ValueError('Dataset Not Loaded') # Change according to convenience\n",
    "        stroke_names = []\n",
    "        for i in self.mridangam_ids:\n",
    "            stroke_names.append(self.mridangam_tracks[i].stroke_name)\n",
    "        stroke_names = np.unique(stroke_names)\n",
    "        return {idx: x for idx, x in enumerate(stroke_names)}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e0e685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T23:25:21.924399Z",
     "iopub.status.busy": "2023-06-27T23:25:21.923846Z",
     "iopub.status.idle": "2023-06-27T23:25:33.476921Z",
     "shell.execute_reply": "2023-06-27T23:25:33.475842Z"
    },
    "papermill": {
     "duration": 11.563904,
     "end_time": "2023-06-27T23:25:33.479585",
     "exception": false,
     "start_time": "2023-06-27T23:25:21.915681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "124MB [00:06, 19.7MB/s]                           \n",
      "100%|██████████| 6976/6976 [00:00<00:00, 7614.80it/s]\n"
     ]
    }
   ],
   "source": [
    "classifier=MuSCl()\n",
    "classifier.load_dataset(\"mridangam_stroke\",download=True) #If first time, change to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec603b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T23:25:33.502306Z",
     "iopub.status.busy": "2023-06-27T23:25:33.501897Z",
     "iopub.status.idle": "2023-06-27T23:25:33.507268Z",
     "shell.execute_reply": "2023-06-27T23:25:33.506262Z"
    },
    "papermill": {
     "duration": 0.018944,
     "end_time": "2023-06-27T23:25:33.509177",
     "exception": false,
     "start_time": "2023-06-27T23:25:33.490233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.listdir(\"/root/mir_datasets/mridangam_stroke/mridangam_stroke_1.5/E/\")\n",
    "#os.listdir(\"/kaggle/input/6june-210/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80d71609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T23:25:33.532454Z",
     "iopub.status.busy": "2023-06-27T23:25:33.532086Z",
     "iopub.status.idle": "2023-06-27T23:25:43.105285Z",
     "shell.execute_reply": "2023-06-27T23:25:43.103480Z"
    },
    "papermill": {
     "duration": 9.587296,
     "end_time": "2023-06-27T23:25:43.107563",
     "exception": false,
     "start_time": "2023-06-27T23:25:33.520267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowLevel.barkbands_kurtosis 23 (23,)\n",
      "lowLevel.barkbands_skewness 23 (23,)\n",
      "lowLevel.barkbands_spread 23 (23,)\n",
      "lowLevel.dissonance 23 (23,)\n",
      "lowLevel.hfc 23 (23,)\n",
      "lowLevel.pitch 23 (23,)\n",
      "lowLevel.pitch_instantaneous_confidence 23 (23,)\n",
      "lowLevel.pitch_salience 23 (23,)\n",
      "lowLevel.silence_rate_20dB 23 (23,)\n",
      "lowLevel.silence_rate_30dB 23 (23,)\n",
      "lowLevel.silence_rate_60dB 23 (23,)\n",
      "lowLevel.spectral_centroid 23 (23,)\n",
      "lowLevel.spectral_complexity 23 (23,)\n",
      "lowLevel.spectral_crest 23 (23,)\n",
      "lowLevel.spectral_decrease 23 (23,)\n",
      "lowLevel.spectral_energy 23 (23,)\n",
      "lowLevel.spectral_energyband_high 23 (23,)\n",
      "lowLevel.spectral_energyband_low 23 (23,)\n",
      "lowLevel.spectral_energyband_middle_high 23 (23,)\n",
      "lowLevel.spectral_energyband_middle_low 23 (23,)\n",
      "lowLevel.spectral_flatness_db 23 (23,)\n",
      "lowLevel.spectral_flux 23 (23,)\n",
      "lowLevel.spectral_kurtosis 23 (23,)\n",
      "lowLevel.spectral_rms 23 (23,)\n",
      "lowLevel.spectral_rolloff 23 (23,)\n",
      "lowLevel.spectral_skewness 23 (23,)\n",
      "lowLevel.spectral_spread 23 (23,)\n",
      "lowLevel.spectral_strongpeak 23 (23,)\n",
      "lowLevel.zerocrossingrate 23 (23,)\n",
      "sfx.inharmonicity 23 (23,)\n",
      "sfx.oddtoevenharmonicenergyratio 23 (23,)\n",
      "tonal.chords_strength 12 (12,)\n",
      "tonal.chords_histogram 24 (24,)\n",
      "tonal.thpcp 36 (36,)\n",
      "lowLevel.barkbands (23, 27)\n",
      "lowLevel.mfcc (23, 13)\n",
      "lowLevel.sccoeffs (23, 6)\n",
      "lowLevel.scvalleys (23, 6)\n",
      "sfx.tristimulus (23, 3)\n",
      "tonal.hpcp (12, 36)\n",
      "tonal.chords_key (2, 1)\n",
      "tonal.chords_scale (5, 1)\n",
      "tonal.key_scale (5, 1)\n",
      "tonal.chords_progression (12, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] Warning: essentia can currently only accept numpy arrays of dtype \"single\". \"audio\" dtype is double. Precision will be automatically truncated into \"single\".\n"
     ]
    }
   ],
   "source": [
    "import essentia.standard as estd\n",
    "\n",
    "filename=r\"/root/mir_datasets/mridangam_stroke/mridangam_stroke_1.5/E/230381__akshaylaya__dhin-e-112.wav\"\n",
    "preprocessor=MuSClPreprocessor()\n",
    "val=preprocessor.BasicPreprocessor(filename,noise_remove=True,normalize_type='librosa',target_peak=0.8)\n",
    "feats=estd.Extractor()(preprocessor.apply_window(val,'hamming'))\n",
    "for name in feats.descriptorNames():\n",
    "    try:\n",
    "        if len(feats[name])>1:\n",
    "            try:\n",
    "                print(name,(len(feats[name]),len(feats[name][0])))\n",
    "            except:\n",
    "                print(name,len(feats[name]),(len(feats[name]),))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b01a9ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T23:25:43.131056Z",
     "iopub.status.busy": "2023-06-27T23:25:43.130373Z",
     "iopub.status.idle": "2023-06-27T23:25:43.135446Z",
     "shell.execute_reply": "2023-06-27T23:25:43.134420Z"
    },
    "papermill": {
     "duration": 0.01904,
     "end_time": "2023-06-27T23:25:43.137380",
     "exception": false,
     "start_time": "2023-06-27T23:25:43.118340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename=r\"/root/mir_datasets/mridangam_stroke/mridangam_stroke_1.5/E/230150__akshaylaya__bheem-e-015.wav\"\n",
    "# preprocessor=MuSClPreprocessor()\n",
    "# val=preprocessor.BasicPreprocessor(filename,noise_remove=True,normalize_type='peak-normalize',target_peak=0.8).shape\n",
    "# dc=dataset.load_tracks()\n",
    "# for track in list(dc.keys())[:5]:\n",
    "#     audio_signal=preprocessor.BasicPreprocessor(dc[track].audio_path,noise_remove=True,normalize_type='peak-normalize',target_peak=0.8)\n",
    "#     if audio_signal.shape!=val:\n",
    "#         print(audio_signal.shape,dc[track].audio_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 62.209227,
   "end_time": "2023-06-27T23:25:44.472923",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-27T23:24:42.263696",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
